# Elasticsearch 세팅 정리
## 설치
> 실행 하기 위해 root 계정 외 다른 계정 사용해야 함.\
> java 8 이상 사용
1. https://www.elastic.co/downloads/elasticsearch 에서 LINUX용 다운
    * yum으로 설치 가능하다고 함...!!
1. /home/elasticsearch/ 경로에 복사
1. tar.gz 압축 풀고
1. `/home/elasticsearch/elasticsearch-7.1.1/bin/elasticsearch-env`에 `JAVA_HOME`을 java8 경로로 변경
    * tar.gz 압축 풀고 확인해 보면 안에 jdk가 포함되어 있다! 이거 써도 될듯!
1. `/home/elasticsearch/elasticsearch-7.1.1/bin/elasticsearch`로 실행
    *  응 오류 발생~
        1. [1]: max file descriptors [4096] for elasticsearch process is too low, increase to at least [65535]
        2. [2]: max number of threads [1024] for user [elasticsearch] is too low, increase to at least [4096]
        3. [3]: max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144]
        4. [4]: the default discovery settings are unsuitable for production use; at least one of [discovery.seed_hosts, discovery.seed_providers, cluster.initial_master_nodes] must be configured
    * 1, 2번 셋팅
        * /etc/security/limits.conf 수정
        ```bash
        ## config for elasticsearch
        ## elasticsearch 유저에게 다음과 같은 권한을 줌.
        elasticsearch hard memlock unlimited # 하드 세팅으로 메모리 락 제한 없도록 설정
        elasticsearch soft memlock unlimited # 소프트 세팅으로 메모리 락 제한 없도록 설정
        elasticsearch hard nofile 65536 # 하드 세팅으로 65536개의 파일을 열어볼 수 있게 설정
        elasticsearch soft nofile 65536 # 소프트 세팅으로 65536개의 파일을 열어볼 수 있게 설정
        elasticsearch hard nproc 65536 # 하드 세팅으로 65536개의 프로시저를 실행할 수 있게 설정
        elasticsearch soft nproc 65536 # 소프트 세팅으로 65536개의 프로시저를 실행할 수 있게 설정
        ```
    * 3번 셋팅
        * /etc/sysctl.conf 수정
        ```bash
        # config for elasticsearch
        vm.max_map_count=262144
        # 설정 후 리붓
        ```
    * 4번 세팅
        * `elasticsearch.yml` 파일 수정
            * 서버 2대로  클러스터 구성
                * elasticsearch.yml_master_2
                * elasticsearch.yml_slave_2
            참조.

# LOGSTASH 세팅 정리
> java 8만 사용\
> 보통 Elastic Search, Logstash, Kibana를 조합하여 사용함.\
> 지금은 일단 DB의 데이터를 Elasticsearch에 넣기 위해 Logstash만 사용
## 설치
* https://www.elastic.co/downloads/logstash 에서 LINUX용 다운
* /home/elasticsearch/ 경로에 복사
* tar.gz 압축 풀고 사용

## MariaDB -> Elasticsearch 마이그레이션
* jdbc 다운로드
    * LOGSTASH_HOME/bin/logstash-plugin install logstash-input-jdbc
    * 자동 다운, 설치가 안돼서 수동 설치함
        * 다운 경로 : https://rubygems.org/gems/logstash-input-jdbc/versions/4.3.13
        * 설치 : `LOGSTASH_HOME/bin/logstash-plugin install FILE_PATH/logstash-input-jdbc-4.3.13.gem`
* config 설정(사용 목적에 따라 다양하게 작성하여 사용)
     * `mysql_to_elasticsearch_conf_file.conf` 참조.`

# 사용법
## 데이터 집어넣기
1. curl 써서 put으로
    *  curl -XPUT -H 'Content-Type: application/json' 'http://10.10.0.41:9200/my_index/my_type/384279?pretty' -d @./my_data.json
1. curl 사용 bulk insert
    *  `curl -XPOST -H 'Content-Type: application/json' 'http://10.10.0.41:9200/my_index/_bulk' --data-binary @my_data_cnt_10000.txt`
    * 파일 형식은 
        ```json
        { "index" : { "_type" : "my_type_name" }}
        {"key1":"value1", "key2":"value2"}
        ...
        ```
        * `sed 'a\\{ "index" : { "_type" : "component" }}' output.txt > output2.txt`
1. Logstash 사용
    * MariaDB -> Elasticsearch 를 위한 logstash config 파일(mysql 도 동일)
        * `mysql_to_elasticsearch_conf_file.conf` 참조.
    * csv파일 -> Elasticsearch 를 위한 logstash config 파일
        * `csv_to_json.conf` 참조
    * 실행
        * `/home/elasticsearch/logstash/bin/logstash -f /home/elasticsearch/logstash/config/mysql_to_elasticsearch_conf_file.conf`
        * `-f` 옵션을 주고 뒤에 conf파일을 명시하면 그 파일 기준으로 실행됨
        * `-f` 옵션 없이 `logstash`만 실행하면 `pipeline.yml`을 참조하여 실행됨.
1. binary log 사용하여 실시간 동기화
    * 해봐야 함.
